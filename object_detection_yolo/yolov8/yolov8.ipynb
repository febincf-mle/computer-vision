{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09e52afa",
   "metadata": {},
   "source": [
    "## YOLOv8 (You Only Look Once, version 8)\n",
    "YOLOv8 is the latest iteration of the YOLO series of object detection models, developed by Ultralytics. It offers state-of-the-art performance with enhanced accuracy, speed, and flexibility, and supports tasks like object detection, image classification, instance segmentation, and pose estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef06830a",
   "metadata": {},
   "source": [
    "### Installation.\n",
    "\n",
    "You can install yolo using pip:\n",
    "\n",
    "```\n",
    "pip install ultralytics\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27bdde2",
   "metadata": {},
   "source": [
    "### Supported Tasks:\n",
    "\n",
    "- Object Detection - Detects objects and their bounding boxes.\n",
    "- Image Classification - Classifies images into predefined categories.\n",
    "- Instance Segmentation - Segments objects within images.\n",
    "- Pose Estimation - Detects human body joints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3830ac6f",
   "metadata": {},
   "source": [
    "### Terminal Implementation.\n",
    "\n",
    "```\n",
    "yolo task=detect mode=predict model=yolov8.pt source=path/to/image/video\n",
    "```\n",
    "\n",
    "- task - The Type of task (detect, segment, classify).\n",
    "- mode - (predict, train, val).\n",
    "- model - The pretrained model to use.\n",
    "- source - The path of the image/video file or the dataset config file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116ccae2",
   "metadata": {},
   "source": [
    "### Config File.\n",
    "\n",
    "The dataset configuration file in YOLOv8 is a YAML file that defines the structure and paths of your dataset. It helps YOLOv8 know where to find your images, labels, and class names during training, validation, and testing.\n",
    "\n",
    "1. Basic Structure of the Dataset Configuration File (data.yaml):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d74ef6",
   "metadata": {},
   "source": [
    "```\n",
    "path: /path/to/dataset          # Root directory of your dataset\n",
    "\n",
    "train: images/train             # Relative path to training images\n",
    "val: images/val                 # Relative path to validation images\n",
    "test: images/test               # Optional: Relative path to test images\n",
    "\n",
    "nc: 3                           # Number of classes (e.g., 3 for cat, dog, bird)\n",
    "\n",
    "names: ['cat', 'dog', 'bird']  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b279981",
   "metadata": {},
   "source": [
    "### Python Implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc12bf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c9fdbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.25M/6.25M [00:00<00:00, 7.57MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/febin/computer-vision/object_detection_yolo/yolov8/assets/people.jpg: 640x448 8 persons, 109.4ms\n",
      "Speed: 8.0ms preprocess, 109.4ms inference, 312.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Results saved to \u001b[1m/home/febin/computer-vision/runs/detect/predict\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       " obb: None\n",
       " orig_img: array([[[213, 205, 192],\n",
       "         [211, 203, 190],\n",
       "         [211, 203, 190],\n",
       "         ...,\n",
       "         [ 21,  36,  39],\n",
       "         [ 21,  36,  39],\n",
       "         [ 21,  36,  39]],\n",
       " \n",
       "        [[213, 205, 192],\n",
       "         [211, 203, 190],\n",
       "         [211, 203, 190],\n",
       "         ...,\n",
       "         [ 20,  35,  38],\n",
       "         [ 20,  35,  38],\n",
       "         [ 19,  34,  37]],\n",
       " \n",
       "        [[213, 205, 192],\n",
       "         [211, 203, 190],\n",
       "         [211, 202, 192],\n",
       "         ...,\n",
       "         [ 21,  36,  39],\n",
       "         [ 20,  35,  38],\n",
       "         [ 19,  34,  37]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  2,   3,   1],\n",
       "         [  2,   3,   1],\n",
       "         [  2,   3,   1],\n",
       "         ...,\n",
       "         [ 79,  80,  41],\n",
       "         [ 80,  80,  44],\n",
       "         [ 78,  78,  42]],\n",
       " \n",
       "        [[  5,   3,   2],\n",
       "         [  5,   3,   2],\n",
       "         [  5,   3,   2],\n",
       "         ...,\n",
       "         [ 78,  79,  39],\n",
       "         [ 80,  81,  42],\n",
       "         [ 78,  79,  40]],\n",
       " \n",
       "        [[  7,   5,   4],\n",
       "         [  6,   4,   3],\n",
       "         [  6,   4,   3],\n",
       "         ...,\n",
       "         [ 78,  79,  39],\n",
       "         [ 81,  82,  43],\n",
       "         [ 78,  79,  40]]], dtype=uint8)\n",
       " orig_shape: (5184, 3456)\n",
       " path: '/home/febin/computer-vision/object_detection_yolo/yolov8/assets/people.jpg'\n",
       " probs: None\n",
       " save_dir: '/home/febin/computer-vision/runs/detect/predict'\n",
       " speed: {'preprocess': 7.961917999978141, 'inference': 109.42589699993732, 'postprocess': 312.2565380000424}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_filepath = os.path.join(os.path.realpath(\".\"), \"assets\", \"people.jpg\")\n",
    "\n",
    "detection_model = YOLO(\"yolov8n.pt\")  \n",
    "detection_model.predict(source=img_filepath, save=True, conf=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccf7d1b",
   "metadata": {},
   "source": [
    "The results will be stored in the runs folder."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".virtualenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
